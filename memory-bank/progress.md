# Progress: CompassAI

## What Works
- Basic structure for both backend and frontend is in place.
- Backend has models, controllers, and routes for various entities.
- Frontend has components and pages for different functionalities.
- Memory Bank initialization is complete with core files created.
- User and Setting models are defined.
- Settings controller provides endpoints for getting and updating global settings.
- SettingsPage.tsx manages various settings on the client side.
- ChatPage.tsx handles chat functionality, including session management and message sending.
- ChatPage.tsx now displays a "Start New Chat" button below the prompt when no chat session is selected, allowing users to easily initiate a new session from the initial view.
- ChatPage.tsx now defaults the "brain" toggle (reasoning/streaming) to the 'on' state.
- ChatPage.tsx speech recognition now dynamically uses Vietnamese ('vi-VN') when the application language is set to Vietnamese ('vi'), otherwise defaults to English ('en-US').
- ChatPage.tsx microphone icon now glows when speech recognition is active, using CSS animations defined in `ChatPage.module.css`.
- ChatPage.tsx input field now uses "Enter" for newline and "Shift+Enter" to send the message.
- **Custom Models Feature:**
    - Admins can create/delete "Custom Providers" in settings.
    - Admins can create/edit "Custom Models" under a provider, linking them to a base model and adding a custom system prompt.
    - **Fixed:** Deleting custom models now works correctly (replaced deprecated `.remove()` with `findByIdAndDelete()` in `backend/controllers/customModels.js`).
    - Chat page model selector now displays both base models and custom models, grouped by provider.
    - Selecting a custom model in the chat page automatically applies its system prompt during AI response generation.
- **Load Last Viewed Session:** The chat page now loads the most recently viewed or interacted with session by default, instead of the most recently created one. This is achieved by tracking and sorting sessions by a `lastAccessedAt` timestamp in the backend.
- **Settings Page UI:** Several admin panels ("User Management", "Model Visibility", "Usage Statistics", "Custom Providers & Models") are now collapsed by default using `<details>` elements for a cleaner initial view.
- **Model Selector Dropdown UI:** Updated text color for model items in light mode to `#34495e` (dark slate blue) for better readability as requested, modified in `ModelSelectorDropdown.module.css`.
- **Navbar "New Chat" Icon:** Added an SVG icon button next to the logo in the Navbar (`Navbar.tsx`). Clicking this button (visible when logged in) triggers a new chat session creation via a global state action (`authStore.ts`) and navigates the user to the new chat.
- **Centralized Session State:** Moved chat session list management (state, loading, errors, fetch/delete actions) from `ChatPage.tsx` to the global store (`authStore.ts`) to fix UI update issues when creating new chats from the navbar. Refactored `ChatPage.tsx` accordingly.
- **Navbar Logo Sidebar Toggle:** Removed the hamburger icon. The logo in `Navbar.tsx` now toggles the sidebar visibility when clicked on chat pages (`/` or `/chat/...`) and acts as a home link on other pages.
- **Navbar Icon Order:** Swapped the positions of the language dropdown and theme toggle icons in `Navbar.tsx`.
- **Multilingual Title Generation:** Refined the backend prompt (`chatMessages.js`) again to instruct the AI to detect the language of the first message, generate the title in Vietnamese if detected, otherwise generate it in English, and respond *only* with the title text.
- **Custom Model Usage Stats Name Fix:** Modified the backend aggregation pipelines in `backend/controllers/stats.js` to include custom model names instead of IDs in the usage statistics.
- **File/Image Previews & Paste Functionality:**
    - Backend (`server.js`) now statically serves the `uploads` directory.
    - Frontend (`ChatPage.tsx`) allows pasting images, selecting files, and shows previews before sending.
    - Uploaded images are displayed in chat messages; other file types are shown as downloadable links.
    - CSS (`ChatPage.module.css`) updated for preview elements.
    - **Fixed:** Corrected image URL construction in `ChatPage.tsx` to properly display uploaded images.
    - **Fixed:** Implemented immediate display of uploaded images in chat by sending the saved user message back from the backend and updating the frontend state accordingly.
- **AI Vision Input (Multimodal):**
    - Backend (`providers.js`) updated to flag vision-capable models (OpenAI GPT-4o/Turbo/4.1 series, Anthropic Claude 3 series, Gemini 1.5 series) and to enrich custom model data with a `baseModelSupportsVision` flag.
    - Backend (`chatMessages.js`) updated to read uploaded images, base64 encode them, and format API requests with image data for supported providers/models.
    - Frontend (`ModelSelectorDropdown.tsx`) updated to display an icon (`üëÅÔ∏è`) next to vision-capable base models and custom models (if their base model supports vision).
    - **Fixed:** Resolved TypeScript build error (`TS2719`) in `ChatPage.tsx` by updating its local `CustomModelData` interface definition to include `baseModelSupportsVision`, aligning it with `ModelSelectorDropdown.tsx` and backend data.
    - **Fixed:** Resolved backend ReferenceError in `chatMessages.js` by ensuring `modelIdentifierForApi` is initialized before use in vision checks.
    - **Fixed:** Corrected OpenAI/Perplexity API request formatting for `image_url` to send an object `{ "url": "data:..." }` instead of a string, resolving 400 errors.
- **UI Update (Advanced Chat Input Redesign - Perplexity Style):**
    - Changed the chat model selection icon in `ModelSelectorDropdown.tsx` from "ü§ñ" to `MdPsychology` and standardized its button styling.
    - Significantly redesigned the chat input area in `ChatPage.tsx`:
        - Implemented a new layout where the textarea moves to a line above the main icon row when its content becomes multi-line or includes newlines.
        - Introduced `isTextareaElevated` state in `ChatPage.tsx` to manage this conditional layout.
        - Reordered icons on the main input row to: Model Selector, Session Memory Toggle, Reasoning Toggle, (inline textarea/placeholder), File Attachment, Voice, Send.
        - The textarea continues to auto-expand vertically based on content.
        - Updated `ChatPage.module.css` with new classes (`.inputControlsElevated`, `.iconRow`, `.elevatedTextarea`) and modified existing styles to support this dynamic two-state layout.
- **S3 File Deletion on Session Delete:**
    - Implemented logic in `backend/controllers/chatSessions.js` (`deleteChatSession` function) to:
        - Identify `ChatMessage` documents with `fileInfo.filename`.
        - Delete the corresponding objects from AWS S3 using `DeleteObjectCommand`.
        - Then proceed to delete `ChatMessage` and `ChatSession` records from MongoDB.
- **`ChatPage.tsx` Cleanup and TypeScript Error Resolution:**
    - Successfully removed extraneous text appended to `ChatPage.tsx` after a previous `write_to_file` operation.
    - **`vite-env.d.ts` Updates:**
        - Added module declarations for `react-router-dom`, `react-markdown`, `remark-gfm`, `react-i18next`, `react-syntax-highlighter`, and `react-syntax-highlighter/dist/esm/styles/prism`.
        - Provided specific type signatures for `useParams`, `useNavigate`, `Link`, `useLocation`, `Routes`, `Route`, `Navigate`, `Outlet`, and `BrowserRouter` from `react-router-dom`.
        - Added `ImportMetaEnv` interface to define Vite environment variables like `VITE_API_BASE_URL`.
    - Most TypeScript module resolution and `import.meta.env` errors in `ChatPage.tsx` have been resolved.
- **Build Error Resolution (Netlify):**
    - Installed `react-icons` as a dependency in `frontend/client/package.json` to fix "Cannot find module 'react-icons/md'" (TS2307) error during Netlify builds.
    - Updated `vite-env.d.ts` to include declarations for `Routes`, `Route`, `Navigate`, `Outlet`, and `BrowserRouter` from `react-router-dom` to resolve TS2305 errors.
- **`ChatPage.tsx` UI Redesign:**
    - Input controls layout updated: Microphone button moved into the main input bar.
    - Share button updated to use `MdShare` / `MdLinkOff` icons.
    - New Chat button in sidebar header updated to use `MdAddCircleOutline` icon and calls `startNewChat` from `authStore`.
    - **Mobile Responsiveness:** Updated `ChatPage.module.css` to keep the Model Selector/Reasoning Toggle row on a single line (`flex-wrap: nowrap;`) for mobile devices, adjusted header margins, and ensured message bubble max-width.
- **User Memory Feature (Personalized Context):**
    - **Backend:**
        - New `UserMemory` Mongoose model created (`backend/models/UserMemory.js`) for storing contexts, global enable status, and max context count. Includes sub-documents for context items with timestamps and a pre-save hook for sorting/trimming.
        - New `userMemoryController.js` (`backend/controllers/userMemoryController.js`) implemented with CRUD operations for memory settings and individual context items.
        - New `userMemoryRoutes.js` (`backend/routes/userMemoryRoutes.js`) established for the controller actions, protected by authentication.
        - User memory routes mounted in `backend/server.js`.
        - `chatMessages.js` controller (`backend/controllers/chatMessages.js`) updated to:
            - Accept a `useSessionMemory` flag from the frontend.
            - Fetch and inject user memory contexts into the LLM prompt if enabled.
            - Implement basic automatic context extraction from short, statement-like user messages.
    - **Frontend:**
        - `api.ts` service (`frontend/client/src/services/api.ts`) updated with interfaces (`UserMemoryData`, `ContextItemData`) and functions for user memory API endpoints.
        - "Personalized Memory" management panel added to `SettingsPage.tsx` (`frontend/client/src/pages/SettingsPage.tsx`), allowing users to:
            - Toggle global memory enablement.
            - Set maximum number of stored contexts.
            - Manually add, view, edit, and delete individual context items.
            - Clear all stored contexts.
        - Session-specific memory toggle (using `MdAutoAwesome` icon) added to `ChatPage.tsx` (`frontend/client/src/pages/ChatPage.tsx`) near the model selector, controlling the `useSessionMemory` flag sent to the backend.

## What's Left to Build
- Thoroughly test the new S3 file deletion feature when deleting chat sessions.
- Further testing and refinement of existing features, especially AI vision input, immediate image display, and the `ChatPage.tsx` UI changes.
- **Thoroughly test the new User Memory feature:**
    - Backend API functionality (CRUD for settings and contexts).
    - Frontend "Personalized Memory" panel in Settings.
    - Frontend session memory toggle on Chat Page.
    - Context injection logic and its impact on LLM responses.
    - Automatic context extraction behavior and accuracy.
    - Uniqueness and recency logic for context storage.
- Address the persistent "Parameter 's' implicitly has an 'any' type" error in `ChatPage.tsx` (around line 694-699) if it causes runtime issues or blocks compilation.
- Confirm which specific Perplexity models support vision via API and update backend/frontend accordingly.
- Potential new features based on user feedback.

## Current Status
The project is actively being developed. Recent work focused on the initial implementation of the User Memory feature, including backend model/controller/routes, frontend UI in Settings and Chat pages, and integration with the chat processing logic. Prior to this, S3 file deletion and various UI/TypeScript enhancements were completed.

## Known Issues
- A persistent TypeScript error ("Parameter 's' implicitly has an 'any' type") remains in `ChatPage.tsx` (around line 694-699) despite multiple attempts to resolve it. This is being monitored.
- Vision support for specific Perplexity models via API is unconfirmed.
- The automatic context extraction for User Memory is currently very basic and may require further refinement for better accuracy and relevance.

## Evolution of Project Decisions
- Added S3 file deletion to the chat session deletion process to manage storage and remove orphaned files.
- Leveraged existing OpenAI vision implementation logic to easily enable support for the GPT-4.1 series models.
- Implemented multimodal support by adding provider-specific logic to the backend message controller.
- Used base64 encoding as the primary method for sending image data to AI APIs.
- Updated the frontend model selector to clearly indicate vision capabilities.
- The `ChatMessage` model already had a suitable `fileInfo` structure, simplifying backend changes for file metadata storage.
- Corrected variable initialization order and API payload formatting in `chatMessages.js` to prevent runtime errors when handling vision models.
- Refactored frontend image URL construction to correctly use the base server URL without the API path prefix.
- Modified backend response and frontend message handling to enable immediate display of uploaded images without page refresh.
- Updated the model selector dropdown icon to `MdPsychology` and standardized its button styling.
- Redesigned chat input for a more dynamic Perplexity-like experience, where the textarea elevates above icons when multi-line, and icons are reordered.
- Extended vision icon display logic in the frontend model selector to custom models by checking a new `baseModelSupportsVision` flag provided by the backend.
- **User Memory Feature:**
    - Adopted a hybrid model for context management (manual + basic automatic extraction).
    - Implemented context storage with a user-configurable maximum limit (default 50), prioritizing recency (`updatedAt`).
    - Uniqueness of contexts is based on an exact text match for the initial version.
    - Provided a global enable/disable setting for the memory feature in user settings.
    - Added a session-specific toggle on the chat page to override memory usage for individual chat sessions.
    - Memory contexts are injected into the system prompt sent to the LLM.
